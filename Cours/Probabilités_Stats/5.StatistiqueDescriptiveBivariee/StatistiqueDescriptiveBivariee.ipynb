{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5deae1",
   "metadata": {},
   "source": [
    "# Statistique Descriptive Bivariée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586b1de",
   "metadata": {},
   "source": [
    "**Librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d385a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe24cc7",
   "metadata": {},
   "source": [
    "On considère dans cette partie une population $\\Omega = { \\omega_1, \\omega_2, \\ldots, \\omega_n }$ avec $n \\geq 3$ et deux caractères numériques $X = [x_1, x_2, \\ldots, x_n]$ et $Y = [y_1, y_2, \\ldots, y_n].$\n",
    "\n",
    "La donnée des deux caractères numériques $X$ et $Y$ équivaut à la donnée d’un **caractère vectoriel** Z\n",
    "\n",
    "$$\n",
    "Z : \\omega_i \\mapsto \n",
    "\\begin{pmatrix}\n",
    "X(\\omega_i) \\\\\n",
    "Y(\\omega_i)\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "x_i \\\\\n",
    "y_i\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "Nous allons analyser graphiquement le lien éventuel entre les valeurs prises par $X$ et celles prises par $Y$.\n",
    "\n",
    "On suppose aussi :\n",
    "\n",
    "- Une probabilité uniforme : $\\mathbb{P}(\\omega_i) = \\frac{1}{n}$ pour tout $i$. \n",
    "\n",
    "(on peut considérer que chaque individu est équiprobable, c’est-à-dire que chaque individu a la même probabilité d’être choisi au hasard.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779360af",
   "metadata": {},
   "source": [
    "### Nuage de points\n",
    "\n",
    "Une première approche graphique consiste à représenter les valeurs de $Y$ en fonction des valeurs de $X$.\n",
    "\n",
    "On trace alors l'ensemble des points $M_i$ de coordonnées :\n",
    "\n",
    "$$\n",
    "M_i = (x_i, y_i)\n",
    "$$\n",
    "\n",
    "Ce graphe est appelé **nuage de points** associé aux caractères \\$X\\$ et \\$Y\\$.\n",
    "\n",
    "---\n",
    "\n",
    "Que permet d’observer un nuage de points ?\n",
    "\n",
    "* **Concentration** ou **dispersion** des données\n",
    "* Une **tendance générale** (croissante, décroissante, etc.)\n",
    "* La présence éventuelle de **valeurs aberrantes** (ou \"outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213425fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1, 2, 3, 4, 5, 6])\n",
    "Y = np.array([2, 4, 5, 4, 5, 7])\n",
    "\n",
    "# Tracé du nuage de points\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(X, Y, \"o\")  # changer \"o\" par \"+\", \".\", etc.\n",
    "plt.title(\"Nuage de points de Y en fonction de X\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43362ad",
   "metadata": {},
   "source": [
    "Point moyen d’un nuage de points\n",
    "\n",
    "Il est défini par :\n",
    "\n",
    "$$\n",
    "G = \\begin{pmatrix} \\overline{x} \\\\ \\overline{y} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "C’est-à-dire le point dont les coordonnées sont les moyennes des valeurs de $X$ et de $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d364a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_moyen = np.mean(X)\n",
    "y_moyen = np.mean(Y)\n",
    "\n",
    "# Affichage du nuage de points\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(X, Y, \"o\", label=\"Nuage de points\")\n",
    "\n",
    "# Affichage du point moyen\n",
    "plt.plot(x_moyen, y_moyen, \"r*\", markersize=12, label=\"Point moyen G\")\n",
    "\n",
    "# Titres et légendes\n",
    "plt.title(\"Nuage de points et point moyen\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Affichage des coordonnées du point moyen\n",
    "print(\"Coordonnées du point moyen G :\", (x_moyen, y_moyen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7659c73d",
   "metadata": {},
   "source": [
    "### Variance et covariance\n",
    "\n",
    "Soit une population :\n",
    "\n",
    "$$\n",
    "\\Omega = \\{ \\omega_1, \\omega_2, \\ldots, \\omega_n \\}\n",
    "$$\n",
    "\n",
    "munie de la probabilité uniforme :\n",
    "\n",
    "$$\n",
    "\\forall \\omega \\in \\Omega, \\quad \\mathbb{P}(\\{ \\omega \\}) = \\frac{1}{n}\n",
    "$$\n",
    "\n",
    "Une **série statistique** $X$ est une application de $\\Omega$ dans $\\mathbb{R}$, donc une **variable aléatoire**.\n",
    "\n",
    "L’**espérance** de $X$ est :\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(X) = \\sum_{i=1}^{n} \\frac{1}{n} X(\\omega_i) = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "C’est simplement la **moyenne empirique** :\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Variance\n",
    "\n",
    "La **variance** de $X$ (par rapport à $\\mathbb{P}$) est :\n",
    "\n",
    "$$\n",
    "V(X) = \\sum_{i=1}^{n} \\frac{1}{n}(x_i - \\bar{x})^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n",
    "$$\n",
    "\n",
    "On note en général l’**écart-type** :\n",
    "\n",
    "$$\n",
    "\\sigma_n(X) = \\sqrt{V(X)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Covariance\n",
    "\n",
    "La **covariance empirique** de $X$ et $Y$ est définie par :\n",
    "\n",
    "$$\n",
    "\\text{cov}(X, Y) = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) = \\mathbb{E}(XY) - \\bar{x} \\bar{y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c1f35",
   "metadata": {},
   "source": [
    "Pour la commande `cov`, l’option `ddof=0` est **essentielle** si l’on souhaite utiliser la **formule mathématique exacte** donnée précedemment.\n",
    "\n",
    "En effet, le facteur utilisé devant la somme est :\n",
    "\n",
    "$$\n",
    "\\frac{1}{n - \\text{ddof}}\n",
    "$$\n",
    "\n",
    "Par défaut, `ddof = 1`, ce qui correspond à une estimation à partir d’un **échantillon**.\n",
    "Mais si on veut la formule exacte pour une population, il faut absolument spécifier `ddof = 0`\n",
    "\n",
    "⚠️ Cette formule n'est pas normalisée !!!\n",
    "\n",
    "\n",
    "Covariance normalisée (corrélation)\n",
    "\n",
    "La **covariance normalisée** entre deux variables aléatoires ( $X$ ) et ( $Y$ ) est appelée **coefficient de corrélation de Pearson**. Elle est définie comme :\n",
    "\n",
    "$\n",
    "\\rho(X, Y) = \\frac{\\text{cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "$\n",
    "\n",
    "où :\n",
    "- ( $\\text{cov}(X, Y)$ ) est la covariance classique,\n",
    "- ( $\\sigma_X$ ) et ( $\\sigma_Y$ ) sont les écarts-types de ( $X$ ) et ( $Y$ ).\n",
    "\n",
    "Cette version est dite **normalisée** car elle donne une valeur comprise entre (-1) et (1), indépendamment des unités de mesure. Cela permet de comparer la force et le sens de la relation linéaire entre deux variables, quelles que soient leurs échelles.\n",
    "\n",
    "- ( $\\rho$ = 1 ) : corrélation linéaire parfaite positive\n",
    "- ( $\\rho$ = 0 ) : pas de corrélation linéaire\n",
    "- ( $\\rho$ = -1 ) : corrélation linéaire parfaite négative\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([5, 7, 3, 9, 6])\n",
    "\n",
    "# Moyenne\n",
    "mean_X = np.mean(X)\n",
    "\n",
    "# Variance sans correction (σ²_n)\n",
    "var_nc = np.var(X, ddof=0)\n",
    "\n",
    "print(\"Moyenne :\", mean_X)\n",
    "print(\"Variance (ddof=0) :\", var_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d05c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([5, 7, 3, 9, 6])\n",
    "Y = np.array([2, 4, 1, 8, 5])\n",
    "\n",
    "# Covariance entre X et Y sans correction\n",
    "cov_XY = np.cov(X, Y, ddof=0)\n",
    "\n",
    "print(\"Matrice de covariance (ddof=0) :\\n\", cov_XY)\n",
    "print(\"Variance de X :\", cov_XY[0, 0])\n",
    "print(\"Variance de Y :\", cov_XY[1, 1])\n",
    "print(\"Covariance entre X et Y :\", cov_XY[0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70aa13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"X\": [5, 7, 3, 9, 6],\n",
    "    \"Y\": [2, 4, 1, 8, 5]\n",
    "})\n",
    "\n",
    "# Variance sans correction\n",
    "print(\"Variances (ddof=0) :\\n\", df.var(ddof=0))\n",
    "\n",
    "# Covariance sans correction\n",
    "print(\"Covariance (ddof=0) :\\n\", df.cov(ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a603a8aa",
   "metadata": {},
   "source": [
    "### Droites de régression\n",
    "\n",
    "Lorsque les points du nuage statistique semblent **presque alignés**, on suppose qu'il existe des coefficients $a$ et $b$ tels que :\n",
    "\n",
    "$$\n",
    "y_i \\approx a x_i + b\n",
    "$$\n",
    "\n",
    "On appelle :\n",
    "\n",
    "* $X$ la **variable explicative**\n",
    "* $Y$ la **variable à expliquer**\n",
    "\n",
    "L’objectif est de trouver la **droite de régression** $y = ax + b$ qui **minimise les erreurs d’ajustement** :\n",
    "\n",
    "Somme des carrés des résidus\n",
    "\n",
    "$$\n",
    "d^2(a, b) = \\frac{1}{n} \\sum_{i=1}^n \\left( y_i - (a x_i + b) \\right)^2\n",
    "$$\n",
    "\n",
    "On cherche à **minimiser** cette quantité pour trouver les meilleurs coefficients $a$ et $b$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x = np.linspace(0, 10, 20)\n",
    "y = 2.5 * x + 1.0 + np.random.normal(0, 3, size=x.shape)\n",
    "\n",
    "# Ajustement par moindres carrés (droite de régression linéaire)\n",
    "coeffs = np.polyfit(x, y, deg=1)  # coeffs = [a, b]\n",
    "a, b = coeffs\n",
    "\n",
    "# Prédictions\n",
    "y_pred = a * x + b\n",
    "\n",
    "# Calcul des résidus\n",
    "residus = y - y_pred\n",
    "\n",
    "# Affichage\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, label='Données observées', color='blue')\n",
    "plt.plot(x, y_pred, label=f'Droite ajustée : y = {a:.2f}x + {b:.2f}', color='red')\n",
    "for i in range(len(x)):\n",
    "    plt.vlines(x[i], y[i], y_pred[i], color='gray', linestyle='dotted')  # traits verticaux = erreurs\n",
    "\n",
    "plt.title(\"Méthode des moindres carrés\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca0fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "np.random.seed(1)\n",
    "x = np.linspace(0, 10, 30)\n",
    "y = 2.5 * x + 1.5 + np.random.normal(0, 4, size=x.shape)\n",
    "\n",
    "a_opt, b_opt = np.polyfit(x, y, 1)\n",
    "a_vals = np.linspace(0.0, a_opt, 100)\n",
    "b_vals = np.linspace(0.0, b_opt, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "ax.scatter(x, y, label=\"Données\", color=\"blue\")\n",
    "line, = ax.plot([], [], 'r-', label=\"Régression animée\")\n",
    "text = ax.text(0.05, 0.95, '', transform=ax.transAxes)\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(min(y) - 5, max(y) + 5)\n",
    "ax.set_title(\"Méthode des moindres carrés (animation)\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "def update(frame):\n",
    "    a = a_vals[frame]\n",
    "    b = b_vals[frame]\n",
    "    y_pred = a * x + b\n",
    "    line.set_data(x, y_pred)\n",
    "    text.set_text(f'y = {a:.2f}x + {b:.2f}')\n",
    "    return line, text\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=len(a_vals), interval=50, blit=True)\n",
    "\n",
    "# enregistrer en GIF\n",
    "ani.save(\"moindres_carres.gif\", writer=PillowWriter(fps=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3bb2d",
   "metadata": {},
   "source": [
    "### Formules de régression (Démonstration en bas de page)\n",
    "\n",
    "* **Pente** de la droite :\n",
    "\n",
    "$$\n",
    "a = \\frac{\\text{Cov}(X, Y)}{\\text{V}(X)}\n",
    "$$\n",
    "\n",
    "* **Ordonnée à l’origine** :\n",
    "\n",
    "$$\n",
    "b = \\bar{y} - a \\bar{x}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Variances et décomposition\n",
    "\n",
    "On a la relation fondamentale suivante :\n",
    "\n",
    "$$\n",
    "\\mathbb{V}(Y) = a^2 \\mathbb{V}(X) + d^2(a, b)\n",
    "$$\n",
    "\n",
    "* Le terme $a^2 \\mathbb{V}(X)$ est la **variance expliquée**\n",
    "* Le terme $d^2(a, b)$ est la **variance résiduelle**\n",
    "\n",
    "Passons de la variance globale à la décomposition point par point.  (Voir démonstration plus bas) \n",
    "\n",
    "Pour chaque observation ( $y_i$ ), on peut décomposer son écart à la moyenne ( $\\bar{y}$ ) comme suit :\n",
    "\n",
    "$$\n",
    "y_i - \\bar{y} = (\\hat{y}_i - \\bar{y}) + (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "avec :\n",
    "\n",
    "- ( $\\hat{y}_i = a x_i + b$ ) : la valeur prédite par la régression,\n",
    "- ( $y_i - \\bar{y}$ ) : l’écart total (variation totale),\n",
    "- ( $\\hat{y}_i - \\bar{y}$ ) : la part **expliquée** par le modèle (variation expliquée),\n",
    "- ( $y_i - \\hat{y}_i$ ) : la part **non expliquée** (résidu, erreur).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données simulées\n",
    "np.random.seed(42)\n",
    "x = np.linspace(0, 10, 20)\n",
    "y = 2 * x + 3 + np.random.normal(0, 4, size=x.shape)\n",
    "\n",
    "# Régression linéaire (moindres carrés)\n",
    "a, b = np.polyfit(x, y, 1)\n",
    "y_pred = a * x + b\n",
    "y_mean = np.mean(y)\n",
    "\n",
    "# Création du graphique\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Nuage de points\n",
    "ax.scatter(x, y, label='Données (y)', color='blue')\n",
    "\n",
    "# Droite de régression\n",
    "ax.plot(x, y_pred, label='Prédictions (ŷ)', color='red')\n",
    "\n",
    "# Moyenne de Y (ligne horizontale)\n",
    "ax.axhline(y_mean, color='green', linestyle='--', label='Moyenne de Y')\n",
    "\n",
    "# Résidus : distance entre y_i et ŷ_i (avec légende une seule fois)\n",
    "for i in range(len(x)):\n",
    "    if i == 0:\n",
    "        ax.plot([x[i], x[i]], [y[i], y_pred[i]], color='gray', linestyle='dotted', label='Résidu (y - ŷ)')\n",
    "    else:\n",
    "        ax.plot([x[i], x[i]], [y[i], y_pred[i]], color='gray', linestyle='dotted')\n",
    "\n",
    "# Variance expliquée : entre ŷ_i et moyenne de Y (avec légende une seule fois)\n",
    "for i in range(len(x)):\n",
    "    if i == 1:\n",
    "        ax.plot([x[i], x[i]], [y_pred[i], y_mean], color='orange', linestyle='dashed', label='Variance expliquée (ŷ - ȳ)')\n",
    "    else:\n",
    "        ax.plot([x[i], x[i]], [y_pred[i], y_mean], color='orange', linestyle='dashed')\n",
    "\n",
    "# Mise en forme\n",
    "ax.set_title(\"Décomposition de la variance en régression linéaire\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26500b9",
   "metadata": {},
   "source": [
    "Coefficient de corrélation linéaire\n",
    "\n",
    "Le **coefficient de corrélation** $\\rho(X, Y)$ mesure la qualité de l’ajustement :\n",
    "\n",
    "$$\n",
    "\\rho(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_n(X)\\sigma_n(Y)}\n",
    "$$\n",
    "\n",
    "On vérifie que :\n",
    "\n",
    "$$\n",
    "\\rho(X, Y)^2 = \\frac{a^2 \\mathbb{V}(X)}{\\mathbb{V}(Y)}\n",
    "$$\n",
    "\n",
    "* Si $|\\rho| \\approx 1$, alors les points sont très bien alignés.\n",
    "* Si $|\\rho| \\approx 0$, il n'y a **aucune corrélation linéaire**.\n",
    "\n",
    "---\n",
    "\n",
    "### Remarque :\n",
    "\n",
    "* Le coefficient $\\rho$ est **sans unité**.\n",
    "* Il est compris entre $-1$ et $1$.\n",
    "* En pratique, une valeur $|\\rho| > 0.85$ est souvent jugée comme **bonne**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945e504",
   "metadata": {},
   "source": [
    "### Tableau de contingence\n",
    "\n",
    "Un **tableau de contingence** donne la **loi conjointe** d’un couple de variables aléatoires discrètes $(X, Y)$, sous **probabilité uniforme**.\n",
    "\n",
    "Soient :\n",
    "\n",
    "* $x_1, x_2, \\dots, x_\\ell$ les valeurs distinctes prises par $X$,\n",
    "* $y_1, y_2, \\dots, y_m$ les valeurs distinctes prises par $Y$,\n",
    "* $f_{i,j}$ la fréquence d'apparition du couple $(x_i, y_j)$.\n",
    "\n",
    "Le tableau est de la forme :\n",
    "\n",
    "| X \\ Y                     | $y_1$           | $y_2$           | … | $y_m$           | Marginale $f_{i,\\bullet}$ |\n",
    "| ------------------------- | --------------- | --------------- | - | --------------- | ------------------------- |\n",
    "| $x_1$                     | $f_{1,1}$       | $f_{1,2}$       | … | $f_{1,m}$       | $f_{1,\\bullet}$           |\n",
    "| $x_2$                     | $f_{2,1}$       | $f_{2,2}$       | … | $f_{2,m}$       | $f_{2,\\bullet}$           |\n",
    "| ...                       | ...             | ...             |   | ...             | ...                       |\n",
    "| $x_\\ell$                  | $f_{\\ell,1}$    | $f_{\\ell,2}$    | … | $f_{\\ell,m}$    | $f_{\\ell,\\bullet}$        |\n",
    "| Marginale $f_{\\bullet,j}$ | $f_{\\bullet,1}$ | $f_{\\bullet,2}$ | … | $f_{\\bullet,m}$ | 1                         |\n",
    "\n",
    "Les marginales se définissent comme :\n",
    "\n",
    "* $f_{i,\\bullet} = \\sum_{j=1}^m f_{i,j}$ (fréquence de $x_i$)\n",
    "* $f_{\\bullet,j} = \\sum_{i=1}^\\ell f_{i,j}$ (fréquence de $y_j$)\n",
    "\n",
    "On remplace parfois les fréquences par les effectifs.\n",
    "\n",
    "---\n",
    "\n",
    "Covariance à partir du tableau\n",
    "\n",
    "La **covariance** se calcule à partir de la loi conjointe $f_{i,j}$ :\n",
    "\n",
    "$$\n",
    "\\mathrm{Cov}(X, Y) = \\sum_{i=1}^{\\ell} \\sum_{j=1}^{m} x_i y_j f_{i,j} - \\bar{X} \\cdot \\bar{Y}\n",
    "$$\n",
    "\n",
    "où :\n",
    "\n",
    "* $\\bar{X} = \\sum_i x_i f_{i,\\bullet}$,\n",
    "* $\\bar{Y} = \\sum_j y_j f_{\\bullet,j}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f52588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Données brutes : effectifs ---\n",
    "effectifs = np.array([\n",
    "    [20, 10],  # Jeunes\n",
    "    [25, 25],  # Adultes\n",
    "    [10, 10]   # Seniors\n",
    "])\n",
    "\n",
    "# Totaux\n",
    "total = effectifs.sum()\n",
    "\n",
    "# Fréquences relatives\n",
    "frequences = effectifs / total\n",
    "\n",
    "# Marginales\n",
    "marge_ligne_eff = effectifs.sum(axis=1)\n",
    "marge_col_eff = effectifs.sum(axis=0)\n",
    "\n",
    "marge_ligne_freq = frequences.sum(axis=1)\n",
    "marge_col_freq = frequences.sum(axis=0)\n",
    "\n",
    "# --- Matrices augmentées ---\n",
    "eff_aug = np.zeros((4, 3), dtype=int)\n",
    "eff_aug[:-1, :-1] = effectifs\n",
    "eff_aug[:-1, -1] = marge_ligne_eff\n",
    "eff_aug[-1, :-1] = marge_col_eff\n",
    "eff_aug[-1, -1] = total\n",
    "\n",
    "freq_aug = np.zeros((4, 3))\n",
    "freq_aug[:-1, :-1] = frequences\n",
    "freq_aug[:-1, -1] = marge_ligne_freq\n",
    "freq_aug[-1, :-1] = marge_col_freq\n",
    "freq_aug[-1, -1] = 1.0\n",
    "\n",
    "# --- Étiquettes ---\n",
    "age_labels = [\"Jeunes\", \"Adultes\", \"Seniors\", \"Σ\"]\n",
    "lecture_labels = [\"Fréquente\", \"Rare\", \"Σ\"]\n",
    "\n",
    "# --- Affichage côte à côte ---\n",
    "fig, axs = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Heatmap des fréquences\n",
    "im1 = axs[0].imshow(freq_aug, cmap='Blues', aspect='auto', origin='upper')\n",
    "axs[0].set_xticks(np.arange(len(lecture_labels)))\n",
    "axs[0].set_yticks(np.arange(len(age_labels)))\n",
    "axs[0].set_xticklabels(lecture_labels)\n",
    "axs[0].set_yticklabels(age_labels)\n",
    "axs[0].set_title(\"Fréquences relatives\")\n",
    "axs[0].set_xlabel(\"Fréquence de lecture\")\n",
    "axs[0].set_ylabel(\"Groupe d'âge\")\n",
    "fig.colorbar(im1, ax=axs[0], fraction=0.046, pad=0.04)\n",
    "for i in range(freq_aug.shape[0]):\n",
    "    for j in range(freq_aug.shape[1]):\n",
    "        axs[0].text(j, i, f\"{freq_aug[i, j]:.2f}\", ha='center', va='center', color='black')\n",
    "\n",
    "# Heatmap des effectifs\n",
    "im2 = axs[1].imshow(eff_aug, cmap='Oranges', aspect='auto', origin='upper')\n",
    "axs[1].set_xticks(np.arange(len(lecture_labels)))\n",
    "axs[1].set_yticks(np.arange(len(age_labels)))\n",
    "axs[1].set_xticklabels(lecture_labels)\n",
    "axs[1].set_yticklabels(age_labels)\n",
    "axs[1].set_title(\"Effectifs\")\n",
    "axs[1].set_xlabel(\"Fréquence de lecture\")\n",
    "axs[1].set_ylabel(\"Groupe d'âge\")\n",
    "fig.colorbar(im2, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "for i in range(eff_aug.shape[0]):\n",
    "    for j in range(eff_aug.shape[1]):\n",
    "        axs[1].text(j, i, str(eff_aug[i, j]), ha='center', va='center', color='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb663c",
   "metadata": {},
   "source": [
    "# Annexe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a988ee",
   "metadata": {},
   "source": [
    "### Démonstration de a et b\n",
    "\n",
    "### Objectif\n",
    "\n",
    "On veut déterminer les coefficients $a$ et $b$ de la droite de régression $y = ax + b$ qui minimisent l’erreur quadratique moyenne :\n",
    "\n",
    "$$\n",
    "d^2(a, b) = \\frac{1}{n} \\sum_{i=1}^n (y_i - (a x_i + b))^2\n",
    "$$\n",
    "\n",
    "On interprète cette minimisation comme une **projection orthogonale** (la distance la plus courte entre un vecteur et un sous-espace (ou un plan) est atteinte par la projection orthogonale.) dans $\\mathbb{R}^n$, muni du produit scalaire :\n",
    "\n",
    "$$\n",
    "\\langle X, Y \\rangle = \\frac{1}{n} \\sum_{i=1}^n x_i y_i = \\mathbb{E}(XY)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation géométrique\n",
    "\n",
    "Soit $Y \\in \\mathbb{R}^n$ le vecteur des $y_i$ et $X$ celui des $x_i$. On cherche à projeter $Y$ sur le plan $\\mathcal{P}$ engendré par $X$ et $\\mathbf{1}_n = (1, \\dots, 1)$.\n",
    "\n",
    "On veut trouver $a$ et $b$ tels que :\n",
    "\n",
    "$$\n",
    "Y = aX + b \\mathbf{1} + R, \\quad \\text{avec } R \\perp X \\text{ et } R \\perp \\mathbf{1}\n",
    "$$\n",
    "\n",
    "Autrement dit, on impose :\n",
    "\n",
    "1. $\\langle Y - (aX + b \\mathbf{1}), X \\rangle = 0$\n",
    "2. $\\langle Y - (aX + b \\mathbf{1}), \\mathbf{1} \\rangle = 0$\n",
    "\n",
    "---\n",
    "\n",
    "### Équation (2) — orthogonalité à $\\mathbf{1}$\n",
    "\n",
    "$$\n",
    "\\langle Y - aX - b\\mathbf{1}, \\mathbf{1} \\rangle = 0\n",
    "$$\n",
    "\n",
    "Développement :\n",
    "\n",
    "$$\n",
    "\\langle Y, \\mathbf{1} \\rangle - a \\langle X, \\mathbf{1} \\rangle - b \\langle \\mathbf{1}, \\mathbf{1} \\rangle = 0\n",
    "$$\n",
    "\n",
    "On remplace :\n",
    "\n",
    "- $\\langle Y, \\mathbf{1} \\rangle = \\bar{y}$\n",
    "- $\\langle X, \\mathbf{1} \\rangle = \\bar{x}$\n",
    "- $\\langle \\mathbf{1}, \\mathbf{1} \\rangle = 1$\n",
    "\n",
    "Donc :\n",
    "\n",
    "$$\n",
    "\\bar{y} - a \\bar{x} - b = 0 \\quad \\Rightarrow \\boxed{b = \\bar{y} - a \\bar{x}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Équation (1) — orthogonalité à $X$\n",
    "\n",
    "$$\n",
    "\\langle Y - aX - b\\mathbf{1}, X \\rangle = 0\n",
    "$$\n",
    "\n",
    "Développement :\n",
    "\n",
    "$$\n",
    "\\langle Y, X \\rangle - a \\langle X, X \\rangle - b \\langle \\mathbf{1}, X \\rangle = 0\n",
    "$$\n",
    "\n",
    "On remplace :\n",
    "\n",
    "- $\\langle Y, X \\rangle = \\mathbb{E}(XY)$\n",
    "- $\\langle X, X \\rangle = \\mathbb{E}(X^2)$\n",
    "- $\\langle \\mathbf{1}, X \\rangle = \\bar{x}$\n",
    "\n",
    "Et on remplace $b$ par $\\bar{y} - a \\bar{x}$ :\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(XY) - a \\mathbb{E}(X^2) - \\bar{x}(\\bar{y} - a \\bar{x}) = 0\n",
    "$$\n",
    "\n",
    "Développement :\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(XY) - a \\mathbb{E}(X^2) - \\bar{x} \\bar{y} + a \\bar{x}^2 = 0\n",
    "$$\n",
    "\n",
    "Regroupement :\n",
    "\n",
    "$$\n",
    "\\mathbb{E}(XY) - \\bar{x} \\bar{y} = a (\\mathbb{E}(X^2) - \\bar{x}^2)\n",
    "$$\n",
    "\n",
    "On reconnaît :\n",
    "\n",
    "- $\\text{Cov}(X, Y) = \\mathbb{E}(XY) - \\bar{x} \\bar{y}$\n",
    "- $\\text{V}(X) = \\mathbb{E}(X^2) - \\bar{x}^2$\n",
    "\n",
    "---\n",
    "\n",
    "### Résultat final :\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "a = \\frac{\\text{Cov}(X, Y)}{\\text{V}(X)}, \\quad\n",
    "b = \\bar{y} - a \\bar{x}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e59edd",
   "metadata": {},
   "source": [
    "### Démonstration de la décomposition de la variance $\\mathbb{V}(Y)$ \n",
    "\n",
    "###  Objectif\n",
    "\n",
    "On souhaite démontrer la décomposition suivante de la variance :\n",
    "\n",
    "$$\n",
    "\\mathbb{V}(Y) = a^2 \\mathbb{V}(X) + d^2(a, b)\n",
    "$$\n",
    "\n",
    "où :\n",
    "- $a^2 \\mathbb{V}(X)$ est la **variance expliquée** par la régression,\n",
    "- $d^2(a, b)$ est la **variance résiduelle**, c’est-à-dire l’erreur moyenne de prédiction.\n",
    "\n",
    "---\n",
    "\n",
    "### Contexte\n",
    "\n",
    "On travaille dans $\\mathbb{R}^n$ muni du **produit scalaire moyen** :\n",
    "\n",
    "$$\n",
    "\\langle u, v \\rangle = \\frac{1}{n} \\sum_{i=1}^n u_i v_i = \\mathbb{E}(UV)\n",
    "$$\n",
    "\n",
    "Soient :\n",
    "- $X = (x_1, \\dots, x_n)$\n",
    "- $Y = (y_1, \\dots, y_n)$\n",
    "- $\\hat{Y} = aX + b\\mathbf{1}$ : prédictions de la régression linéaire\n",
    "- $R = Y - \\hat{Y}$ : **résidus**\n",
    "\n",
    "---\n",
    "\n",
    "### Idée géométrique (Pythagore)\n",
    "\n",
    "La droite de régression $aX + b$ est la **projection orthogonale** de $Y$ sur l’espace des fonctions linéaires en $X$.\n",
    "\n",
    "Ainsi, on a l’orthogonalité :\n",
    "\n",
    "$$\n",
    "\\langle R, \\hat{Y} \\rangle = 0\n",
    "$$\n",
    "\n",
    "Donc, par le théorème de Pythagore :\n",
    "\n",
    "$$\n",
    "\\|Y\\|^2 = \\|\\hat{Y}\\|^2 + \\|R\\|^2\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Interprétation des normes\n",
    "\n",
    "Les normes au carré correspondent à des variances dans notre cadre :\n",
    "\n",
    "- $\\|Y\\|^2 = \\mathbb{V}(Y)$\n",
    "- $\\|\\hat{Y}\\|^2 = \\mathbb{V}(\\hat{Y})$\n",
    "- $\\|R\\|^2 = \\mathbb{V}(Y - \\hat{Y}) = d^2(a, b)$\n",
    "\n",
    "---\n",
    "\n",
    "### Calcul de $\\mathbb{V}(\\hat{Y})$\n",
    "\n",
    "On a :\n",
    "\n",
    "$$\n",
    "\\hat{Y} = aX + b\n",
    "$$\n",
    "\n",
    "Et comme ajouter une constante ne change pas la variance :\n",
    "\n",
    "$$\n",
    "\\mathbb{V}(\\hat{Y}) = \\mathbb{V}(aX + b) = a^2 \\mathbb{V}(X)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "En combinant toutes les étapes :\n",
    "\n",
    "$$\n",
    "\\mathbb{V}(Y) = \\mathbb{V}(\\hat{Y}) + \\mathbb{V}(Y - \\hat{Y})\n",
    "$$\n",
    "\n",
    "donc :\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathbb{V}(Y) = a^2 \\mathbb{V}(X) + d^2(a, b)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92563b0",
   "metadata": {},
   "source": [
    "### Passer de la variance globale à une décomposition point par point\n",
    "\n",
    "On part de la définition de la variance de $Y$ :\n",
    "\n",
    "$$\n",
    "\\mathbb{V}(Y) = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\bar{y})^2\n",
    "$$\n",
    "\n",
    "L'objectif est de décomposer chaque terme $(y_i - \\bar{y})^2$ en deux composantes : une **expliquée** par le modèle, et une **résiduelle**.\n",
    "\n",
    "---\n",
    "\n",
    "Étape 1 : Décomposition de l’écart total\n",
    "\n",
    "On part de l’identité algébrique suivante, qui est toujours vraie :\n",
    "\n",
    "$$\n",
    "y_i - \\bar{y} = (\\hat{y}_i - \\bar{y}) + (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "C’est une simple réécriture de $y_i = \\hat{y}_i + r_i$, où $r_i = y_i - \\hat{y}_i$ est le **résidu**.\n",
    "\n",
    "---\n",
    "\n",
    "Étape 2 : Développement du carré\n",
    "\n",
    "En élevant au carré des deux côtés :\n",
    "\n",
    "$$\n",
    "(y_i - \\bar{y})^2 = (\\hat{y}_i - \\bar{y})^2 + (y_i - \\hat{y}_i)^2 + 2(\\hat{y}_i - \\bar{y})(y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Puis, en moyennant cette expression sur $i$ (i.e. en sommant puis en divisant par $n$) :\n",
    "\n",
    "$$\n",
    "\\mathbb{V}(Y) = \\mathbb{V}(\\hat{Y}) + \\mathbb{V}(Y - \\hat{Y}) + \\frac{2}{n} \\sum_{i=1}^n (\\hat{y}_i - \\bar{y})(y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Étape 3 : Le terme croisé disparaît\n",
    "\n",
    "Dans une régression linéaire, les **résidus sont orthogonaux aux prédictions**, donc :\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n (\\hat{y}_i - \\bar{y})(y_i - \\hat{y}_i) = 0\n",
    "\\quad \\Rightarrow \\quad\n",
    "\\langle \\hat{Y} - \\bar{y}, Y - \\hat{Y} \\rangle = 0\n",
    "$$\n",
    "\n",
    "Cela repose sur deux faits :\n",
    "- Le vecteur constant $\\bar{y} \\cdot \\mathbf{1}$ appartient à l’espace des prédictions $\\text{Vect}(X, \\mathbf{1})$,\n",
    "- Donc $\\hat{Y} - \\bar{y} \\cdot \\mathbf{1}$ appartient aussi à cet espace,\n",
    "- Et les résidus $R = Y - \\hat{Y}$ sont orthogonaux à cet espace.\n",
    "\n",
    "D'où l’annulation du terme croisé.\n",
    "\n",
    "---\n",
    "\n",
    "Étape 4 : Décomposition de la variance\n",
    "\n",
    "Il reste alors :\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathbb{V}(Y) = \\mathbb{V}(\\hat{Y}) + \\mathbb{V}(Y - \\hat{Y})\n",
    "}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Étape 5 : Revenir à une égalité point par point\n",
    "\n",
    "L'égalité suivante découle directement de l'identité algébrique vue plus haut :\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "y_i - \\bar{y} = (\\hat{y}_i - \\bar{y}) + (y_i - \\hat{y}_i)\n",
    "}\n",
    "$$\n",
    "\n",
    "C’est la **décomposition de l’écart total** en :\n",
    "\n",
    "- une part **expliquée par le modèle** : $\\hat{y}_i - \\bar{y}$\n",
    "- une part **non expliquée (résidu)** : $y_i - \\hat{y}_i$\n",
    "\n",
    "---\n",
    "\n",
    "Récapitulatif interprétatif :\n",
    "\n",
    "Pour chaque observation $y_i$, on a :\n",
    "\n",
    "$$\n",
    "y_i - \\bar{y} = (\\hat{y}_i - \\bar{y}) + (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "| Terme                          | Interprétation                      |\n",
    "|-------------------------------|-------------------------------------|\n",
    "| $y_i - \\bar{y}$               | Écart total à la moyenne            |\n",
    "| $\\hat{y}_i - \\bar{y}$         | **Part expliquée** par la régression |\n",
    "| $y_i - \\hat{y}_i$             | **Résidu** (erreur, part non expliquée) |\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
